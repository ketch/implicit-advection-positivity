\documentclass[a4paper]{article}

%% Language and font encodings
\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{enumitem}

%% Sets page size and margins
\usepackage[a4paper,top=3cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}

%% Useful packages
\usepackage{amsmath,amsthm,amssymb}
\usepackage{graphicx}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{remark}{Remark}
\newtheorem{example}{Example}
\newtheorem{corollary}{Corollary}




\newcommand{\dt}{\Delta t}
\newcommand{\dx}{\Delta x}
\newcommand{\te}{\theta}
\newcommand{\nul}{\nu_L(k,\theta)}
\newcommand{\nur}{\nu_R(k,\theta)}
\newcommand{\yl}{y_L(k,\theta)}
\newcommand{\yr}{y_R(k)}
\newcommand{\nplus}{\mathbb{N}^+}
\newcommand{\rr}{\mathbb{R}}
\newcommand{\Por}{P_{R,k}(y)}
\newcommand{\Pol}{P_{L,k,\te}(y)}
\newcommand{\cP}{{\cal{P}}}
\newcommand{\cD}{{\cal{D}}}
\newcommand{\cF}{{\cal{F}}}
\newcommand{\cS}{{\cal{S}}}



\newcommand\blfootnote[1]{%
  \begingroup
  \renewcommand\thefootnote{}\footnote{#1}%
  \addtocounter{footnote}{-1}%
  \endgroup
}




\title{Positivity of implicit discretizations of the advection equation}
\author{Yiannis Hadjimichael\thanks{\texttt{@} }\and David I. Ketcheson\thanks{\texttt{david.ketcheson@kaust.edu.sa}}\and Lajos L\'oczi\thanks{{\texttt{LLoczi@inf.elte.hu}}, Department of Numerical Analysis, E\"otv\"os Lor\'and University, and Department of Differential Equations, Budapest University of Technology and Economics, Hungary. Project no.~ED\_18-1-2019-0030 (Application-specific highly reliable IT solutions) has been implemented with the support provided from the National Research, Development and Innovation Fund of Hungary, financed under the Thematic Excellence Programme funding scheme.}}

\begin{document}
\maketitle
\begin{abstract}
In this work we analyze---from the viewpoint of positivity
preservation---certain discretizations of a fundamental partial differential
equation, the one-dimensional advection equation with periodic boundary
condition. The full discretization is obtained by coupling a second-order
centered difference scheme in space with an arbitrary $\te$-method in time
(including the forward and backward Euler methods, and a second-order method by
choosing $\te\in [0,1]$ suitably). The full discretization yields a
two-parameter family of circulant matrices $M\in\mathbb{R}^{m\times m}$, 
where $m$ is the number of spatial grid points, and each matrix entry is a
rational function in $\te$ and $\nu$. Here $\nu>0$ denotes the CFL number,
being proportional to the ratio between the temporal and spatial discretization
step sizes. The entrywise non-negativity of the matrix $M$---which is
equivalent to the positivity preservation of the full discretization
scheme---is investigated via discrete Fourier analysis and some low-order
linear recursions. We get that positivity preservation is impossible for even
values of $m$, but the case $m=2k+1$ is more subtle. It turns out,
surprisingly, that positivity preservation is recovered for odd values of $m$
provided that $\te\ge 1/2$ and $\nu$ is bounded by two positive constants (the
upper bound can sometimes be $+\infty$). The interplay between $m$, $\te$ and
$\nu$ governing non-negativity of the matrix $M$ is explicitly described in
terms of roots of certain sparse polynomials. %Finally, some connections with 
%non-negative inverse eigenvalue problems are pointed out.
\end{abstract}
\blfootnote{This work was supported by the King Abdullah University of Science and Technology (KAUST), 4700
Thuwal, 23955-6900, Saudi Arabia.}

\section{Background and motivation}
In this work we investigate the positivity of some discretizations of the advection equation
\begin{subequations} \label{advection}
\begin{align}
U_t (x,t)& = a U_x(x,t) & x\in[0,1], t>0, \\
U(x,0) & = U_0(x), \\
U(0,t) & = U(1,t),
\end{align}
\end{subequations}
where $U:\mathbb{R}\times [0,+\infty)\to\mathbb{R}$ is the unknown function, $U_0:\mathbb{R}\to\mathbb{R}$ is a given differentiable initial function, and $a>0$ is a constant. 
The exact solution of the Cauchy problem \eqref{advection}, given by $U(x,t) =
U_0(\{x+a t\})$ (where $\{\cdot\}$ denotes the fractional part), is positivity preserving; i.e.
%\begin{align} \label{implies-positivity}
\[
\forall x, \forall t\quad\quad U_0(x) \ge 0 \implies U(x,t) \ge 0.
\]
%\end{align}
Positivity is often important in this context, since $U$ may represent a
concentration or density that cannot be negative.

\begin{remark}
Following the usual terminology, the term {\emph{positivity}} in the context of {positivity preservation} is always meant in the weak sense; i.e.~it means {\emph{non-negativity}}. 
\end{remark}


Finite difference semi-discretization of \eqref{advection} yields a system of ODEs
\begin{align} \label{semi-discrete}
    u'(t) & = \frac{a}{\dx}Lu(t),
\end{align}
where $u:\mathbb{R}\to\mathbb{R}^m$, $L\in\mathbb{R}^{m\times m}$ is a circulant matrix  \cite[Section 5.16]{matmat}, and $\dx>0$ denotes the spatial discretization step size.  
If one uses an upwind spatial discretization
\begin{subequations}
\label{upwind1}
\begin{align} 
    L_{i,i}  & := -1,\quad\quad L_{i,i+1} :=  1 \ \ \ \ 1\le i < m \\
    L_{m,1} & := 1
\end{align}
\end{subequations}
then the exact solution of \eqref{semi-discrete} is also positivity
preserving. Moreover, a corresponding full discretization will be positivity preserving too,
under an appropriate time step size restriction $0<\dt\le\dt_0$
if the forward (explicit) Euler method or any strong stability preserving
method \cite{SSPbook} is used in time, see, e.g.~\cite{posconv}.  

The upwind discretization \eqref{upwind1} is only of order one; it is natural
to use a more accurate spatial discretization. A second-order scheme is
obtained with the centered difference
\begin{subequations}
\label{centered-difference}
\begin{align}
    L_{i,i-1} & := -\frac{1}{2},\quad\quad L_{i,i+1} :=  \frac{1}{2} \\
    L_{1,m} & := -\frac{1}{2}, \quad \quad L_{m,1} := \frac{1}{2}.
\end{align}
\end{subequations}
However, this semi-discretization is not positivity preserving, since the
matrix $L$ has at least one negative off-diagonal entry \cite[Chapter I,
Theorem 7.2]{hundsdorferverwer}.
This implies that any consistent full discretization based on \eqref{centered-difference}
must fail to preserve positivity under sufficiently small step sizes $\dt>0$.
Indeed, a full discretization based on the scheme \eqref{centered-difference}
and forward Euler in time is not positivity preserving for any step size.

On the other hand, interestingly, using \eqref{centered-difference} with backward (implicit) 
Euler time integration, one generally observes positivity preservation
under \emph{large} step sizes.  To investigate the differences between the behavior
of the forward and backward Euler methods, we will study the $\theta$-method \cite[Chapter IV.3]{hairerwanner}
\begin{align}\label{firsttheta}
    u^{n+1} = u^n + \frac{a\dt}{\dx}((1-\theta)Lu^n + \theta Lu^{n+1}).
\end{align}
For $\te\in[0,1]$, this family of time integrators includes both Euler methods as limiting cases: the forward Euler method for $\te=0$, the backward 
 Euler method for $\te=1$, and the only second-order $\te$-method for $\te=1/2$. 







%Thus our main focus is on a discretization of \eqref{advection} that is
%centered in space and backward in time.  For various reasons, this
%is not a method that is recommended in practice, but it is an application
%of some of the most fundamental discretizations to one of the most fundamental
%partial differential equations (PDEs), so its behavior seems to be of
%independent interest.

%Any linear one-step discretization of a time-dependent PDE in one spatial
%dimension with $m$ grid points in space yields an approximate solution given by
%an iteration of the form
%where $M$ is a fixed $m\times m$ matrix.

\subsection{Structure of the paper and main results}
In Section \ref{sectiondiscFourier} ... In Section \ref{sectioncentered} ... Theorem \ref{thm1} 

In Section \ref{explsect} ...  To reveal more information on the signs of the matrix entries $M_{1,j}$. Therefore, in this section, we first rewrite the  entries in a certain algebraic form by invoking some low-order linear recursions. Then, in Section \ref{nonnegsect}, we will give conditions for $M_{1,j}\ge 0$ in terms of the parameters $\te$ and $\nu$.
The results obtained in this section are independent of the question of non-negativity, and may be applicable in other contexts as well.\\
\boxed{\text{LL POINT OUT: Corollary 1, asymptotic bounds, and the relevant figures, definitions}}

Finally, in Section \ref{SNIEP} ...\\

The computations in this work have been carried out by using Wolfram \textit{Mathematica} version 11.


\subsection{Notation}
Throughout the paper, the set of positive integers is denoted by $\nplus$, the complex imaginary unit is $\imath$, the identity matrix is $I\in\rr^{m\times m}$, and to emphasize the dimensions of a matrix, we will sometimes write, for example, $L_{m\times m}$.
The symbol $M\ge 0$ means that  $M_{i,j}\ge 0$ for every entry $1\le i, j\le m$ of the matrix $M\in\mathbb{R}^{m\times m}$. Finally, as is customary in the context of space-time discretizations of partial differential equations, superscripts of $u$, e.g.~in \eqref{firsttheta}, are not exponents but denote time discretization steps.  





%$M\not\ge 0$ means there is at least one negative entry $M_{i,j}<0$.\\


\subsection{\boxed{\text{Some useful sentences to reuse, then remove this subsection}}}
SENTENCES FROM \cite{posconv}---------------------------------------
In this work we do not deal with the influence of boundary conditions, so for simplicity
we consider periodic boundaries.\\
SENTENCES FROM \cite{posconv}---------------------------------------
We focus on the application of this technique to the initial-boundary-value problem given
by the hyperbolic conservation law below, together with positive initial and boundary data.
A common approach to solving hyperbolic conservation laws numerically is to discretize in
space with a slope or flux limiter, and in time with an explicit Runge--Kutta (explicit RK,
or ERK) method. It is natural to ask whether the positivity property is retained under this
discretization. This question is usually analyzed by using Harten's theorem
to show positivity under explicit Euler integration, and then applying a higher-order strong
stability preserving (SSP) method in time .... This can be thought of as a method-of-lines
positivity analysis, in which the spatial and temporal discretizations are analyzed separately.
In the present work, we perform a direct positivity analysis of fully discretized schemes,
obtaining stronger results than what can be achieved by considering only Harten's theorem
and SSP methods. These results provide a theoretical basis for some empirical observations in
..., wherein various Runge--Kutta integrators preserved strong stability properties under
step sizes much larger than those suggested by the existing theory.
--------------------------------------------------------------------------------\\




\section{Discrete Fourier analysis}\label{sectiondiscFourier}
From here on, we consider the problem \eqref{advection} on the domain $x\in[0,1]$
with periodic boundary condition $U(0,t)=U(1,t)$.  Finite difference discretization
in space leads to \eqref{semi-discrete} with $u_j\approx u(j\dx)$ for $1\le j\le m$. 
The circulant matrix $L\in\mathbb{R}^{m\times m}$ has the eigendecomposition
%\begin{align}
\begin{align} \label{eigen}
    L  = \cF \Lambda \cF^*,
\end{align}
%\end{align}
where the (unitary) matrix of eigenvectors $\cF$ has entries
%\begin{align}
\[
    f_{j,\ell}  := \frac{1}{\sqrt{m}}\exp(\imath  (j-1) \xi_\ell)  \quad\quad (1 \le j, \ell \le m),
\]
%\end{align}
and $\Lambda$ is the diagonal matrix of eigenvalues $\lambda_\ell$, which depends on the
particular finite difference method chosen.  Here $\xi_\ell$ are evenly spaced angles 
%\begin{align}
\[
    \xi_\ell  := \frac{2\pi(\ell-1)}{m} \quad\quad (1 \le \ell \le m),
\]
such that $\exp(\imath\xi_\ell)$ are the $m$th roots of unity.
%\end{align}
Applying a one-step time
discretization with stability function $R:\mathbb{C}\to\mathbb{C}$ to \eqref{semi-discrete} leads to
the iteration
\begin{align} \label{M}
    u^{n+1} & = M u^n,
\end{align}
where 
\begin{equation}\label{Mdualdef}
M:=R(\nu L)=\cF R(\nu \Lambda) \cF^*, 
\end{equation}
and $\nu:=a\dt/\dx>0$ is the CFL number.  
Then it is easily seen that 
\[
\text{positivity preservation of the fully discrete numerical solution}\quad \Longleftrightarrow \quad M\ge 0.
\]
For one-step methods, $R$ is a rational function, and products and inverses of circulant matrices are also circulant \cite[Fact 5.16.7]{matmat}, so
$M$ is also a real, circulant matrix.
Thus it is defined completely by the entries of its first row, which
are given by
\begin{align} \label{M-entries}
    M_{1,j} & = \frac{1}{m} \sum_{\ell=1}^m R(\nu\lambda_\ell) \exp(-\imath(j-1)\xi_\ell) \quad\quad (1\le j\le m).
\end{align}

\subsection{Centered in space, $\theta$-method in time}\label{sectioncentered}
In what follows we assume $3\le m\in\nplus$. Consider the case of a 3-point centered difference approximation in space:
%\begin{align}
\[
    U_x\Big|_{x=x_j} \approx \frac{u_{j+1}-u_{j-1}}{2\dx},
\]
%\end{align}
so that $L\in\mathbb{R}^{m\times m}$ is a circulant matrix with entries $(-1/2, 0, 1/2)$ on the central
three diagonals:
\begin{equation}\label{Ldef}
L:=\left(
\begin{array}{cccccc}
 0 & \frac{1}{2} & 0  & \cdots & 0 & -\frac{1}{2} \\
 -\frac{1}{2} & 0 & \frac{1}{2} &  \cdots & 0 & 0 \\
 0 & -\frac{1}{2} & 0 &  \ddots & 0 & 0\\
 \vdots  & \vdots  & \ddots  & \ddots & \ddots & \vdots \\
  0 & 0 & \cdots  & -\frac{1}{2} & 0 & \frac{1}{2} \\
 \frac{1}{2} & 0 & \cdots & 0 & -\frac{1}{2} & 0 \\
\end{array}
\right).
\end{equation}
It is known that the eigenvalues of $L$ are 
\begin{equation}\label{Leigenvalues}
\lambda_\ell=\imath \sin(\xi_\ell)\quad (1\le\ell\le m).
\end{equation}
%Let us consider first the backward Euler method.
%The eigenvalues for this semi-discretization are $\lambda_j = \imath\sin\xi_j$.
%If we use the backward Euler method in time, we have $R(z) = (1-z)^{-1}$, so
%\eqref{M-entries} gives the entries of $M$ as
%\begin{align} \label{firstrow}
%    M_{1,j} & = \frac{1}{m} \sum_{k=1}^m \frac{\exp\left(-i(j-1)\xi_k\right)}{1-\nu i \sin\xi_k}.
%\end{align}
%If $m$ is even, then these entries cannot all be positive.
%
%\begin{lemma}
%    If $m$ is even, then $M_{1,m} < 0$.
%\end{lemma}
%\begin{proof}
%    From \eqref{firstrow} we have
%    \begin{align}  \label{M12}
%        M_{1,m} & = \frac{1}{m} \sum_{k=1}^m \frac{ \exp(-i(m-1)\xi_k)}{1-\nu i \sin\xi_k}
%                  = \frac{1}{m} \sum_{k=1}^m \frac{ \exp(i\xi_k)}{1-\nu i \sin\xi_k}
%                  = \frac{1}{m} \sum_{k=1}^m \frac{\cos \xi_k - \nu \sin^2 \xi_k}{1+\nu^2 \sin^2 \xi_k}.
%    \end{align}
%    The expression on the right is obtained by multiplying by the complex
%    conjugate of the denominator and taking the real part (since $M$ is a real matrix).
%    Due to symmetry, when $m$ is even,
%    \begin{align*}
%        \sum_{k=1}^m \frac{\cos \xi_k}{1+\nu^2\sin^2\xi_k}  = \sum_{k=1}^{m/2} \frac{\cos \xi_k + \cos(\xi_k+\pi)}{1+\nu^2\sin^2\xi_k} = 0.
%    \end{align*}
%    Thus 
%    \begin{align*} 
%        M_{1,m} & = \frac{1}{m} \sum_{k=1}^m \frac{- \nu \sin^2 \xi_k}{1+\nu^2 \sin^2 \xi_k} < 0.
%    \end{align*}
%\end{proof}
%Using similar expressions, it can in fact be shown that, for $m$ even, we have
%$M_{1,2j}<0$ for $1\le j \le m/4$; in other words, approximately one fourth of
%the entries of $M$ are negative, no matter the value of $\nu$.  All of these
%negative entries tend to zero as $\nu \to \infty$.
%
%Meanwhile, if $m$ is odd...
The stability function $R$ for the $\theta$-method \cite[Chapter IV.3]{hairerwanner} is
\begin{align}\label{R}
    R(z)  := \frac{1+(1-\theta)z}{1-\theta z},
\end{align}
so with the centered difference in space we get from \eqref{M-entries} for $1\le j\le m$ that
\begin{equation}\label{matrix_entries}
\begin{split}
	M_{1,j} &= \frac{1}{m} \sum_{\ell=1}^m \frac{1+(1-\theta)\nu \imath\sin(\xi_\ell)}
		{1-\theta\nu \imath\sin(\xi_\ell)}\exp\left(-\imath(j-1)\xi_\ell\right) \\
		&= \frac{1}{m} \sum_{\ell=1}^{m} \frac{\left(1-\theta(1-\theta)\nu^2\sin^2(\xi_\ell)\right)
		\cos((j-1)\xi_\ell) + \nu \sin(\xi_\ell)\sin((j-1)\xi_\ell)}{1+\theta^2\nu^2 \sin^2(\xi_\ell)} \\
		&\quad - \frac{\imath}{m} \sum_{\ell=1}^{m} \frac{\left(1-\theta(1-\theta)\nu^2\sin^2(\xi_\ell)
		\right)\sin((j-1)\xi_\ell) - \nu \sin(\xi_\ell)\cos((j-1)\xi_\ell)}
		{1+\theta^2\nu^2 \sin^2(\xi_\ell)}.
\end{split}
\end{equation}
Note that the angles $\{(j-1)\xi_\ell\}_{\ell=1}^m$ are symmetric about the $x$-axis if $m$ is odd, and
also if $m$ is even and $j$ is odd.
If both $m$ and $j$ are even, then the angles are symmetric about the origin.
Therefore, we have that
\begin{align*}
	\sum_{\ell=1}^{m} \sin((j-1)\xi_\ell) = 0 \qquad \text{and} \qquad
		\sum_{\ell=1}^{m} \sin(\xi_\ell)\cos((j-1)\xi_\ell) = 0,
\end{align*}
for all $1\le j\le m$  and for any value of $m$.
Moreover the factors
$\frac{1-\theta(1-\theta)\nu^2\sin^2(\xi_\ell)}{1+\theta^2\nu^2 \sin^2(\xi_\ell)}$
and $\frac{\nu}{1+\theta^2\nu^2 \sin^2(\xi_\ell)}$ in \eqref{matrix_entries} keep this symmetry.
Thus, the imaginary part of \eqref{matrix_entries} vanishes, yielding $M_{1,j}\in\mathbb{R}$ for all $j$,
as expected.
So for $1\le j\le m$ we get
%Since $ M_{1,j}\in\mathbb{R}$, the imaginary part of the above sum vanishes, so for $1\le j\le m$ we also
%have
%\begin{align}\label{firstrow-theta}
\[
  M_{1,j}  = \frac{1}{m} \sum_{\ell=1}^{m} \frac{\left(1-\theta(1-\theta)\nu^2\sin^2(\xi_\ell)\right)
  \cos((j-1)\xi_\ell) + \nu \sin(\xi_\ell)\sin((j-1)\xi_\ell)}{1+\theta^2\nu^2 \sin^2(\xi_\ell)}.
\]
%\end{align}
This leads to the following expressions for the first, second and last entries of the first
row of $M$:
\begin{align*}
	M_{1,1} & = \frac{1}{m} \sum_{\ell=1}^m \frac{1-\theta(1-\theta)\nu^2\sin^2(\xi_\ell)}
		{1+\theta^2\nu^2\sin^2(\xi_\ell)}, \\
	M_{1,2} & = \frac{1}{m} \sum_{\ell=1}^{m} \frac{\left(1-\theta(1-\theta)\nu^2\sin^2(\xi_\ell)\right)
		\cos(\xi_\ell) + \nu \sin^2(\xi_\ell)}{1+\theta^2\nu^2 \sin^2(\xi_\ell)}, \\
	M_{1,m} & = \frac{1}{m} \sum_{\ell=1}^m \frac{\left(1-\theta(1-\theta)\nu^2\sin^2(\xi_\ell)\right)
		\cos(\xi_\ell) - \nu \sin^2 (\xi_\ell)}{1+\theta^2\nu^2 \sin^2 (\xi_\ell)}.
\end{align*}
These entries will have a special role in the forthcoming analysis. 
We distinguish two cases.
\begin{description}[style=unboxed,leftmargin=0cm]
\item [{Case 1:} $m$ is {even}.]
\item \noindent By using similar symmetry arguments as before, we conclude that for {even} $m=2k\ge 4$
the entries of matrix $M$ are given by
\begin{align*}
	M_{1,j} = \begin{cases}
				\displaystyle
				\frac{1}{m} \sum_{\ell=1}^{m}\frac{\left(1-\theta(1-\theta)\nu^2\sin^2(\xi_\ell)
					\right)\cos((j-1)\xi_\ell)}{1+\theta^2\nu^2\sin^2(\xi_\ell)}, &\mbox{if } j
					\text{ is odd}, \\[20pt]
				\displaystyle
				\frac{1}{m} \sum_{\ell=1}^{m} \frac{\nu \sin(\xi_\ell)\sin((j-1)\xi_\ell)}
					{1+\theta^2\nu^2 \sin^2 (\xi_\ell)}, &\mbox{if } j \text{ is even}.
			  \end{cases}
\end{align*}
Considering  the above expression for $j = m$ we have
\begin{align*}
    M_{1,m} & =  \frac{1}{m} \sum_{\ell=1}^{m} \frac{- \nu \sin^2 (\xi_\ell)}{1+\theta^2\nu^2 \sin^2 (\xi_\ell)} < 0.
\end{align*}
%$\bullet$ For \emph{even} $m=2k\ge 4$, consider the above expression for $M_{1,m}$. The sum over the first term in the numerator vanishes due to symmetry, and $\sin(\xi_1)=0$, so we have
%\begin{align*}
%    M_{1,m} & =  \frac{1}{m} \sum_{\ell=2}^{m} \frac{- \nu \sin^2 (\xi_\ell)}{1+\theta^2\nu^2 \sin^2 (\xi_\ell)} < 0.
%\end{align*}
Thus the discretization using centered differences in space and the $\theta$
method in time cannot preserve positivity when $m$ is even, regardless of the
values of $\theta\in[0,1]$ and $\nu>0$.

We can arrive at the same conclusion by observing that
for any $m=2k\ge 4$ we have $M_{1,2}=-M_{1,m}$, so that one of
these entries must always be negative.
%\begin{remark}
%By using similar symmetry arguments, one can prove that for any $m=2k\ge 4$ we have
%$M_{1,2}=-M_{1,m}$, which also shows that $M\ge 0$ is impossible for $\te\in[0,1]$ and $\nu>0$.
%\end{remark}
\item [{Case 2:} $m$ is {odd}.]
\item \noindent Let us now consider the case of {odd} $m=2k+1\ge 3$. Then $\sin(\xi_\ell)\ne0$ for
$2\le\ell\le m$.
 Writing
\begin{align*} 
	M_{1,1} & = \frac{1}{m} \left(1 + \sum_{\ell=2}^{m} \frac{1-\theta(1-\theta)\nu^2\sin^2(\xi_\ell)}
		{1+\theta^2\nu^2\sin^2(\xi_\ell)}\right) \\
	M_{1,j} & = \frac{1}{m} \left(1 + \sum_{\ell=2}^{m} \frac{(1-\theta(1-\theta)\nu^2\sin^2(\xi_\ell))
		\cos((j-1)\xi_\ell) + \nu \sin(\xi_\ell)\sin((j-1)\xi_\ell)}{1+\theta^2\nu^2 \sin^2(\xi_\ell)}
		\right) \quad (j\ge 2),
\end{align*}
and taking $\nu \to +\infty$ with $m$ and $\te\in(0,1]$ fixed, we find that
\begin{align*} 
    M_{1,1}^\infty := \lim_{\nu \to +\infty} M_{1,1} & = \frac{1}{m} \left(1 - \sum_{\ell=2}^m \frac{1-\theta}{\theta}\right) =  1-\frac{m-1}{m\theta}\\
    M_{1,j}^\infty := \lim_{\nu \to +\infty} M_{1,j} & = \frac{1}{m} \left(1 - \sum_{\ell=2}^m \frac{1-\theta}{\theta}\cos((j-1)\xi_\ell)\right) = \frac{1}{m} \left(1+\frac{1-\theta}{\theta}\right) = \frac{1}{m\theta} \quad\quad (j\ge 2).
\end{align*}
We see that
\[M_{1,j}^\infty>0 \text{ for all } 2\le j\le m \text{ and } \te\in(0,1],
\]
 while 
\[M_{1,1}^\infty>0 \quad\Longleftrightarrow\quad \theta>\frac{m-1}{m}.
\]
Thus for fixed $m\ge 3$ and $\theta>\frac{m-1}{m}$, the matrix $M$ is non-negative 
if $\nu>0$ is large enough.

We now show that $M\ge 0$ also holds for $\theta=\frac{m-1}{m}$ with $m$ fixed and for $\nu>0$ large enough. 
Clearly, we only need to verify the non-negativity of entry $M_{1,1}$ for $\nu>0$ large enough. 
In fact, for $\theta=\frac{m-1}{m}$ and for \emph{any} $\nu>0$ we have $M_{1,1}> 0$. To see this, consider a summand with $2\le\ell\le m$ in $M_{1,1}$: 
\[
 \frac{1-\theta(1-\theta)\nu^2\sin^2(\xi_\ell)}{1+\theta^2\nu^2\sin^2(\xi_\ell)}\Big|_{\theta=\frac{m-1}{m}}=
 \frac{m^2-(m-1) \nu ^2 \sin ^2\left(\xi _\ell\right)}{m^2+(m-1)^2 \nu ^2 \sin ^2\left(\xi _\ell\right)}=:\varphi(\nu,\ell).
\]
Its partial derivative with respect to $\nu$ is
\[
\partial_\nu\varphi(\nu,\ell)=-\frac{2 (m-1) m^3 \nu  \sin ^2\left(\xi _\ell\right)}{\left(m^2+(m-1)^2 \nu ^2 \sin ^2\left(\xi _\ell\right)\right)^2}<0,
\]
and $\varphi(0,\ell)=1$, hence the function $\nu\mapsto M_{1,1}=\frac{1}{m} \left(1 + \sum_{\ell=2}^{m} \varphi(\nu,\ell)\right)$ is positive at $\nu=0$, strictly decreases, and its limit when $\nu\to +\infty$ is $M_{1,1}^\infty=0$, completing the proof of the claim.\\

Summarizing the above, we have proved the following for any $m\ge 3$, $\te\in[0,1]$ and
$\nu>0$.
\end{description}
\begin{theorem}\label{thm1}
Consider the advection equation with periodic boundary condition discretized using centered
differences in space and the $\theta$-method in time with $m$ spatial grid points.  
The discretization takes the form \eqref{M},
where\\
(i) if $m$ is even, then $M$ has at least one negative entry;\\
(ii) if $m$ is odd and $\theta\in\left[\frac{m-1}{m},1\right]$, then for large enough $\dt$ all
entries of $M$ are non-negative.
\end{theorem}

\noindent\rule{10cm}{0.4pt}\\
\noindent\rule{10cm}{0.4pt}\\
This result is rather unusual, since in numerical analysis one typically makes
statements about small enough mesh parameters, and parity is rarely important.
We see that the full discretization can be positivity preserving only if $m$ is
odd.  Furthermore, we see that from the point of view of positivity preservation,
it is better to use larger values of both $\dt$ and $\dx$.

\textbf{Y.H.: In my opinion we could avoid any discussion about $\dt$ or $\dx$ and say that for large
enough CFL numbers in theorem 1, the matrix $M$ is non-negative.
In general for hyperbolic problems $\dt$ is proportional to  $\dx$.}
\textbf{D.K.: Since we reference $m$ we are discussing $\dx$ anyway, and with $m$ fixed then
$\nu$ and $\dt$ vary proportionally to one another.  I prefer using $\dt$ since then both
ODE and PDE readers will have a good idea of what we mean.}

WE CAN emphasize the following again: positivity preservation of the fully discrete numerical solution  
$\Longleftrightarrow  M\ge 0$

MAYBE WE CAN REUSE THESE SENTENCES:
The exact solution of the resulting semi-discrete
system \eqref{semi-discrete} is not positive invariant, so (given an appropriate
positive initial condition) any consistent time discretization will yield
negative values for small enough time steps.  Here we investigate whether
it is possible to ensure positive invariance for large time steps.\\
\noindent\rule{10cm}{0.4pt}\\
\noindent\rule{10cm}{0.4pt}

A refinement of Theorem \ref{thm1} for odd values of $m$ will be given at the end of Section \ref{section3}, see Theorem \ref{thm2}.
As for the interval $\theta\in\left[\frac{m-1}{m},1\right]$ appearing in Theorem \ref{thm1}, see also 
Figures \ref{fig_variousk}--\ref{fig_boundary}.


\begin{remark} 
In the formulae leading to Theorem \ref{thm1} we used a trigonometric representation of the matrix 
\emph{entries} $M_{1,j}$. Here we highlight a related approach to studying the non-negativity of $M$ by
relying only on the \emph{eigenvalues} $\sigma_\ell$ ($1\le \ell\le m$) of $M$. According to
\eqref{Mdualdef}, \eqref{Leigenvalues} and \eqref{R}, we have
\[
\sigma_\ell:=R(\nu\lambda_\ell)=\frac{1+ (1-\theta )\nu \imath \sin \left(\xi _\ell\right)}{1- \theta\nu \imath  \sin \left(\xi _\ell\right)}.
\]
The main question in the context of \emph{non-negative inverse eigenvalue problems} is to 
find (necessary or sufficient) conditions for a set $\Sigma:=\{\sigma_1,\ldots,\sigma_m\}\subset\mathbb{C}$ to be the spectrum of \emph{some} non-negative $m \times m$ matrix.
%In our situation, of course, the eigenvalues of $M(m,\te,\nu)$ also depend on the parameters $\te\in[0,1]$ and $\nu>0$. For this reason, a direct application of such a theorem to extract information on $\te$ and $\nu$ is not straightforward, so below we present only some examples. 
One such condition is the following. It is known \cite[Chapter 4]{nonnegmatr} that if $\Sigma$ is the spectrum of 
an $m \times m$ non-negative matrix, then 
\begin{equation}\label{sigmampq}
\forall\, p, q \in\nplus:\quad\quad 0\le \left(\sum_{j=1}^m \sigma_j^{\,p}\right)^q\le m^{q-1} \sum_{j=1}^m \sigma_j^{\,p q}.
\end{equation}
For example, for $m=5$ and $\te=1$, \eqref{sigmampq} with  $p\in\{1,\ldots,9\}$ and $q\in\{2,3\}$ yields the lower bounds
\begin{equation}\label{nustartpq}
\nu\ge \nu_{*}(p,q),
\end{equation}
where the approximate values of $\nu_{*}(p,q)$ are given below:
\[
\begin{array}{|c|c|c|c|c|c|c|c|c|c|}
\hline
\nu_{*}(p,q) & p=1 & p=2 & p=3 & p=4 & p=5 & p=6 & p=7 & p=8 & p=9 \\
\hline
q=2 & 3.0074 & 1.462 & 0.9669 & 0.7219 & 0.5753 & 0.4778 & 0.4082 & 0.3563 & 0.3160 \\
\hline
q=3 & 2.1497 & 1.0269 & 0.6694  & 0.4941 & 0.3907 & 0.3227  & 0.2749  & 0.2393  &  0.2119 \\
\hline
\end{array}
\]
As we see, the necessary condition \eqref{sigmampq}---valid for \emph{any} non-negative matrix---already 
implies that there are positive \emph{lower} bounds on $\nu$, although these bounds are not optimal. 
%\begin{remark}
%In the actual computations of the values of $\nu_{*}(p,q)$, we made use of the property 
%\[
%\forall\, r\in\nplus:\quad\quad\sum_{j=1}^m \sigma_j^{\,r}=\mathrm{trace}(M^r)\] 
%to avoid computing the eigenvalues as functions of $\nu$, and to convert \eqref{sigmampq} into
%\begin{equation}\label{48converted}
%\left(\mathrm{trace}(M^p)\right)^q\le m^{q-1} \mathrm{trace}(M^{p q}),
%\end{equation}
%see Figure \ref{fig_eigen1}. The resulting high-degree inequalities in $\nu$ have then been solved: for $p=9$ and $q=3$, for example, the rational functions in $\nu$ on both sides of \eqref{48converted} have numerator and denominator degrees 108.
%\end{remark}
%\begin{remark}
%In the definition of $\nu_R(2,1)$ in \eqref{nurdef}, the constant $y_R(2)$ can be simplified to a degree 6 algebraic number, and $\nu_R(2,1)$ itself is a degree 3 algebraic number.
%\end{remark}
%\begin{figure}
%\begin{center}
%\includegraphics[width=0.5\textwidth]{fig_eigenvalues1.pdf}
%\caption{The right- and left-hand sides of inequality \eqref{48converted}---as functions of $\nu$ with $m=5$, $\te=1$, $p=1$ and $q=2$---are shown as solid and dashed curves, respectively. The positive intersection point of the curves occurs at $\nu_{*}(1,2)\approx 3.0074$.}\label{fig_eigen1}
%\end{center}
%\end{figure}

It is possible to sharpen the lower bounds in \eqref{nustartpq} by making use of some more specific results. 
%In order to facilitate a comparison, we consider again the case $m=5$, $\te=1$. 
%The inequality \eqref{sigmampq} holds for any non-negative matrix. However, 
We know in addition that the matrix $M$ is \emph{circulant}, which leads us to the realm of 
\emph{structured non-negative inverse eigenvalue problems}. For example, 
the spectra of non-negative circulant matrices have been characterized (with a necessary \emph{and} sufficient condition) in \cite[Theorem 10]{rojosoto}. From this theorem we get (still for $m=5$ and $\te=1$) the lower bound
\[
\nu\ge 3.9173.
\]
%To keep our presentation simple, we do not reproduce this theorem here due to its technical details, only give a short overview.
%Suppose that the matrix $M$ is non-negative and circulant. Then \cite[Theorem 10]{rojosoto} shows
%that the Perron--Frobenius root (that is, the non-negative eigenvalue equal to the spectral radius of $M$, which exists due to the classical Perron--Frobenius theorem \cite{nonnegmatr})
%that  $\sigma_1\ge $ cannot be
%Interestingly, for $m=4$ and $\te=1$, the application of \cite[Theorem 10]{rojosoto} already shows that $M(4,1,\nu)\ge 0$ cannot hold for any $\nu>0$.
As we will see, the precise lower bound for this matrix---according to our Theorem \ref{thm2} with $k=2$ and $\te=1$---is
\[
\nu\ge \nu_R(2,1)\approx 4.4111.
\]
\end{remark}

\begin{remark}
It is not restrictive to assume $a>0$ in \eqref{advection}. If we assumed $a<0$ instead, then the results of Theorems \ref{thm1} and \ref{thm2} would remain valid (together with Figures \ref{fig_variousk}--\ref{fig_boundary}, for example), with all the arguments in their proofs being essentially the same.  For example, as we will see in Section \ref{section3}, the non-negativity of (the first row of) matrix $M$ is governed by the elements $M_{1,1}$ and $M_{1,m}$ for $a>0$ and $m$ odd---this would change to elements $M_{1,1}$ and $M_{1,2}$ for $a<0$ and $m$ odd.
\end{remark}

%\subsection{Structured non-negative inverse eigenvalue problems}





\section{An algebraic characterization of the matrix entries}\label{section3}

The results of Section \ref{sectiondiscFourier} are based on the eigendecomposition of the full discretization matrix $M=\cF R(\nu \Lambda) \cF^*$. In this section, instead of using trigonometric functions, we give an algebraic description of the matrix entires by exploiting the relation $M=R(\nu L)$ in \eqref{Mdualdef} with $L$ defined in \eqref{Ldef}.
Explicitly, this means 
\begin{equation}\label{Mdef}
M(m,\te,\nu)=(I-\te\nu L)^{-1}(I+(1-\te)\nu L)\in\mathbb{R}^{m\times m},
\end{equation}
but the dependence of $M$ on its parameters will often be suppressed. 

It is trivial that for $\te=0$ we have $M(m,0,\nu)=I+\nu L$, hence $M\ge 0$ cannot hold for any $\nu>0$. The case $m=2k$ has been discussed in Section \ref{sectioncentered}. Thus, throughout the rest of this section, we can assume that 
\begin{equation}\label{genassump}
\boxed{ 
m=2k+1\quad (k\in\nplus), \ \ \ \nu>0 \text{\ \  and\ \  } 0<\te\le 1.}
\end{equation}

\subsection{Explicit description of the matrix entries for odd values of $m$}\label{explsect}

% When $m\ge 3$ is odd, it is not apparent how to use the trigonometric representation \eqref{firstrow-theta} to reveal information on the signs of the matrix entries $M_{1,j}$. Therefore, in this section, we first rewrite the  entries in a certain algebraic form by invoking some low-order linear recursions. Then, in Section \ref{nonnegsect}, we will give conditions for $M_{1,j}\ge 0$ in terms of the parameters $\te$ and $\nu$.
%\begin{remark}
%The results obtained in this section are independent of the question of non-negativity, and may be applicable in other contexts as well. 
%\end{remark}




To illustrate the structure of $M$, we present its first row (as a vector, and with the common denominator of the entries in front of it) for the smallest values of $m$. 
\begin{example}\label{example1} 
%For $m=2$, 
%\[\frac{1}{{\theta ^2 \nu ^2}/{4}+1}\left(-\frac{1}{4} \theta ^2 \nu ^2+\frac{\theta  \nu ^2}{4}+1,\theta  \nu -\frac{\nu }{2}\right),\]
For $m=3$ the first row of \eqref{Mdef} is 
\[
\frac{1}{{3 \theta ^2 \nu ^2}/{4}+1}\left(\frac{3 \theta ^2 \nu ^2}{4}-\frac{\theta  \nu ^2}{2}+1,\frac{\theta  \nu ^2}{4}+\frac{\nu }{2},\frac{\theta  \nu ^2}{4}-\frac{\nu }{2}\right),
\]
while for $m=5$ we have 
\[
\frac{1}{{5 \theta ^4 \nu ^4}/{16}+{5 \theta ^2 \nu ^2}/{4}+1}\left(\frac{5 \theta ^4 \nu ^4}{16}-\frac{\theta ^3 \nu ^4}{4}+\frac{5 \theta ^2 \nu ^2}{4}-\frac{\theta  \nu ^2}{2}+1,\right.
\]
\[
\left.\frac{\theta ^3 \nu
   ^4}{16}+\frac{\theta ^2 \nu ^3}{4}+\frac{\nu }{2},\frac{\theta ^3 \nu ^4}{16}-\frac{\theta ^2 \nu ^3}{8}+\frac{\theta  \nu ^2}{4},\frac{\theta ^3
   \nu ^4}{16}+\frac{\theta ^2 \nu ^3}{8}+\frac{\theta  \nu ^2}{4},\frac{\theta ^3 \nu ^4}{16}-\frac{\theta ^2 \nu ^3}{4}-\frac{\nu }{2}\right).
\]

\end{example}


Each element of $M$ is a rational function in the variables $\te$ and $\nu$. From \eqref{Mdef} it is clear that 
\begin{equation}\label{M1jPjkDk}
M_{1,j}=\frac{\cP_{j,k}(\te,\nu) }{\cD_k(\te,\nu)}\quad\quad(j=1,2,\ldots,2k+1),
\end{equation}
where $\cP_{j,k}$ and $\cD_{k}$ are certain bivariate polynomials in $\te$ and $\nu$, and 
\begin{equation}\label{dendet}
\cD_k:=\det\left(I_{(2k+1)\times(2k+1)}-\te\nu L_{(2k+1)\times(2k+1)}\right).
\end{equation}
\begin{remark}
The subscripts of $\cP_{j,k}$ thus refer to the position of the polynomial within the first row of $M$, and the size of $M\in\mathbb{R}^{(2k+1)\times(2k+1)}$, respectively.
\end{remark}


The key to describing $M$ algebraically is the observation that the polynomials $\cP_{j,k}$ and $\cD_{k}$ satisfy certain low-order linear recursions with constant coefficients. As already indicated by Section \ref{sectioncentered}, the leftmost entry ($j=1$) behaves differently than the rest ($2\le j\le 2k+1$).


\begin{remark}
 \textit{Mathematica}'s  {\tt{FindLinearRecurrence}} command proved to be an efficient tool for discovering these linear recursions. 
\end{remark}
First, let us introduce some new variables. On the one hand, as suggested by Example \ref{example1}, it seems convenient to set
\[
\mu:=\te^2\nu^2>0.
\]
Then, due to the sign assumptions, $\sqrt{\mu}=\te\nu$. On the other hand, as we will soon see, the polynomial 
\[
\kappa ^2-\kappa  \left(1+\frac{\mu }{2}\right)+\frac{\mu ^2}{16}
\]
will appear as a (factor of a) characteristic polynomial, and its roots are
\begin{equation}\label{kappa12}
\kappa_{1,2}=\frac{2+\mu \pm 2 \sqrt{\mu +1}}{4}=\left(\frac{\sqrt{1+\mu}\pm 1}{2}\right)^2.
\end{equation}
This motivates us to introduce yet another variable, which will further simplify our exposition. We set
\begin{equation}\label{ydef01}
y:=\frac{\sqrt{1+\mu}-1}{\sqrt{\mu}}=\frac{\sqrt{1+\te^2\nu^2}-1}{\te\nu}\in (0,1).
\end{equation}
It is seen that the transformation
\[
(0,+\infty)\ni\mu \longleftrightarrow y\in(0,1)
\]
is a bijection. Moreover, the following (inverse) relations 
\[
\mu=\left(\frac{2y}{1-y^2}\right)^2,
\]
\[\mu y^2=2+\mu-2\sqrt{1+\mu},\]
\[\mu/y^2=2+\mu+2\sqrt{1+\mu},\]
and
\begin{equation}\label{fromytonu}
\nu=\frac{2y}{1-y^2}\cdot\frac{1}{\te}
\end{equation}
are easily verified. We can now start describing the entries of the first row of $M$.
\begin{remark}
Although the expressions $\cP_{j,k}$ and $\cD_{k}$ will become in general rational functions in the variable $y$, we still call them polynomials (referring to their structure in the original variables $\te$ and $\nu$). 
\end{remark}
$\bullet$ The polynomials $\cD_k$. By carrying out some determinant expansions, we see that the determinants \eqref{dendet} obey the second-order parametric recursion
\begin{equation}\label{Dkrec}
\cD_{k+2}=\left(1+\frac{\mu}{2}\right)\cD_{k+1}-\frac{\mu^2}{16}\cD_k
\end{equation}
with initial conditions
\[
\cD_1=1+\frac{3\mu}{4}, \quad \cD_2=1+\frac{5\mu}{4}+\frac{5\mu^2}{16}
\]
(cf.~Example \ref{example1}). After solving this recursion, we obtain
\[
\cD_k=\left(\frac{\sqrt{1+\mu}+1}{2}\right)^{2 k+1}- \left(\frac{\sqrt{1+\mu}-1}{2}\right)^{2 k+1},
\]
which, in terms of the variable $y$, becomes
\begin{equation}\label{expldet}
\cD_k=\frac{1-y^{4 k+2}}{\left(1-y^2\right)^{2 k+1} }.
\end{equation}

$\bullet$  The polynomials $\cP_{1,k}$. They satisfy the recursion 
\[
\cP_{1,k+2}=\left(1+\frac{\mu}{2}\right)\cP_{1,k+1}-\frac{\mu^2}{16}\cP_{1,k},
\]
that is, with coefficients being the same as in \eqref{Dkrec}, but with initial conditions
\[
\cP_{1,1}=1+\frac{3 \mu }{4}-\frac{\mu /\theta}{2  }, \quad \cP_{1,2}=1+\frac{5 \mu }{4}+\frac{5 \mu ^2}{16}-\frac{\mu/\theta }{2  }-\frac{\mu ^2/\theta}{4  }
\]
(cf.~Example \ref{example1}). By solving this recursion we derive that
\begin{equation}\label{P1kexpl}
\cP_{1,k}=\frac{\Pol}{  \left(1+y^2\right)\left(1-y^2\right)^{2 k+1}\theta},
\end{equation}
where the numerator is 
\begin{equation}\label{poldef}
\Pol:=-\theta  y^{4 k+4}-(\theta -2) y^{4 k+2}+(\theta -2) y^2+\theta.
\end{equation}
\begin{remark}
Here, the subscript $L$ stands for \emph{leftmost}. This polynomial will play a special role in the next section.
\end{remark}


$\bullet$  The polynomials $\cP_{2,k}$. They satisfy a third-order recursion in the variable $k$,
\begin{equation}\label{cP2rec}
\cP_{2,k+3}=\left(1+\frac{3\mu}{4}\right)\cP_{2,k+2}-\left(\frac{\mu }{4}+\frac{3 \mu ^2}{16}\right)\cP_{2,k+1}+\frac{\mu ^3}{64}\cP_{2,k},
\end{equation}
with initial conditions 
\[
\cP_{2,1}=\left(\frac{1}{2}+\frac{\sqrt{\mu }}{4}\right) \nu, \quad \cP_{2,2}=\left(\frac{1}{2}+\frac{\mu }{4}+\frac{\mu ^{3/2}}{16}\right) \nu,
\]
\[
\cP_{2,3}=\left(\frac{1}{2}+\frac{\mu }{2}+\frac{3 \mu ^2}{32}+\frac{\mu ^{5/2}}{64}\right) \nu.
\]
The  characteristic polynomial of recursion \eqref{cP2rec} is 
\[
\kappa ^3-\kappa ^2 \left(1+\frac{3 \mu }{4}\right)+\kappa  \left(\frac{\mu }{4}+\frac{3 \mu ^2}{16}\right)-\frac{\mu ^3}{64}=\left(\kappa-\frac{\mu }{4}\right)\left(\kappa ^2-\kappa  \left(1+\frac{\mu }{2}\right)+\frac{\mu ^2}{16}\right),
\]
hence the characteristic roots are $\kappa_{1,2}$ as in \eqref{kappa12}, and $\kappa_3={\mu }/{4}$. Based on this, one easily obtains the explicit solution as
\begin{equation}\label{cP2kexpl}
\cP_{2,k}=\frac{\nu  \left(1-y^2\right)^{1-2 k} \left(1+y^{2 k-1}+y^{2 k+1}-y^{4 k}\right)}{2 \left(1+y^2\right)}.
\end{equation}


$\bullet$  The polynomials $\cP_{3,k}$. They satisfy the same third-order recursion in the variable $k$ as \eqref{cP2rec},
\[
\cP_{3,k+3}=\left(1+\frac{3\mu}{4}\right)\cP_{3,k+2}-\left(\frac{\mu }{4}+\frac{3 \mu ^2}{16}\right)\cP_{3,k+1}+\frac{\mu ^3}{64}\cP_{3,k},
\]
but with initial conditions 
\[
\cP_{3,1}=\left(-\frac{1}{2}+\frac{\sqrt{\mu }}{4}\right) \nu, \quad \cP_{3,2}=\left(\frac{\sqrt{\mu} }{4}-\frac{\mu}{8}+\frac{\mu ^{3/2}}{16}\right) \nu,
\]
\[
\cP_{3,3}=\left(\frac{\sqrt{\mu }}{4}-\frac{\mu ^2}{32}+\frac{3 \mu ^{3/2}}{16}+\frac{\mu ^{5/2}}{64}\right) \nu.
\]
The explicit solution of this recursion is
\begin{equation}\label{cP3kexpl}
\cP_{3,k}=\frac{\nu  \left(1-y^2\right)^{1-2 k} \left(y-y^{2 k-2}+y^{2 k+2}+y^{4 k-1}\right)}{2 \left(1+y^2\right)}.
\end{equation}
\begin{remark}
We note that, for any \emph{fixed} $j\ge 2$, the polynomials $\cP_{j,k}$ satisfy the same third-order recursion \eqref{cP2rec} in the variable $k$, with triplets of initial conditions depending on $j$. However, we cannot use this approach to proceed, since setting up the initial conditions would require, among others, the knowledge of the  polynomials $\cP_{j,1}$ (for $j=2, 3$),  $\cP_{j,2}$ (for $j=4, 5$), $\cP_{j,3}$ (for $j=6, 7$), and so on. 
\end{remark}



$\bullet$  The polynomials $\cP_{j,k}$ ($4\le j\le 2k+1$, $k\ge 2$). They satisfy the following second-order recursion in the variable $j$ when $k$ is \emph{fixed} (hence having only finitely many terms for a particular $k$):  
\[
\cP_{j+2,k}=-\frac{2}{\sqrt{\mu }}\cP_{j+1,k}+\cP_{j,k}.
\]
For the initial conditions of this final recursion, we use the general forms of $\cP_{2,k}$ and $\cP_{3,k}$ in \eqref{cP2kexpl} and \eqref{cP3kexpl} to get for any $k\ge 1$ and $2\le j\le 2k+1$ that 
\begin{equation}\label{Pjkexpl}
\cP_{j,k}=\frac{\nu  \left(1-y^2\right)^{1-2 k}}{2 \left(1+y^2\right)}P_{j,k}(y), 
\end{equation}
where the polynomials $P_{j,k}$ are defined as
\begin{equation}\label{Pjky}
P_{j,k}(y):=(-1)^{j-1} y^{4 k+2-j}+y^{2 k-1+j}+(-1)^j y^{2 k+1-j}+y^{j-2}.
\end{equation}
As a special case, we set
\[
\Por:=P_{2k+1,k}(y),
\]
in other words we have
\begin{equation}\label{pordef}
\Por=y^{4 k}+y^{2 k+1}+y^{2 k-1}-1,
\end{equation}
where the subscript $R$ stands for \textit{rightmost}.


\begin{remark}
As a by-product, we have obtained the following set of identities by comparing the trigonometric and algebraic representations presented so far. They are also interesting from a structural point of view: although the number of terms in the trigonometric sums increases as $k$ gets larger, the polynomials in $y$ are sparse polynomials (also known as lacunary polynomials or fewnomials)---the number of terms does not increase as the polynomial degree increases.
\end{remark}
\begin{corollary}
With $M$ defined in \eqref{Mdef}, $\te>0$, $\nu>0$, $k\in\nplus$, $y=\frac{\sqrt{1+\te^2\nu^2}-1}{\te\nu}$, and $\xi_\ell  = \frac{2\pi(\ell-1)}{2k+1}$, we have that
\[
 \frac{1}{2k+1} \sum_{\ell=1}^{2k+1} \frac{1+\imath(1-\theta)\nu \sin(\xi_\ell)}{1-\imath\theta\nu  \sin(\xi_\ell)}=
\]
\[
M_{1,1}=\frac{\cP_{1,k}}{\cD_k}=
\]
\[
\frac{-\theta  y^{4 k+4}-(\theta -2) y^{4 k+2}+(\theta -2) y^2+\theta}{  \left(1+y^2\right)\left(1-y^{4 k+2}\right)\theta}.
\]
Moreover, for $j=2, 3, \ldots, 2k+1$ we have that
\[
\frac{1}{2k+1} \sum_{\ell=1}^{2k+1} \frac{1+\imath(1-\theta)\nu \sin(\xi_\ell)}{1-\imath\theta\nu \sin(\xi_\ell)}\exp\left(-\imath(j-1)\xi_\ell\right)=
\]
\[
M_{1,j}=\frac{\cP_{j,k}}{\cD_k}=
\]
\[
\frac{\nu  \left(1-y^2\right)^2 }{2 \left(1+y^2\right) \left(1-y^{4 k+2}\right)}\Big((-1)^{j-1} y^{4 k+2-j}+y^{2 k-1+j}+(-1)^j y^{2 k+1-j}+y^{j-2}\Big).
\]
In particular,
\[
\prod_{\ell=1}^{2k+1} (1-\imath\theta\nu \sin(\xi_\ell))=\cD_k=
\]
\[
\left(\frac{\sqrt{1+\te^2\nu^2}+1}{2}\right)^{2 k+1}- \left(\frac{\sqrt{1+\te^2\nu^2}-1}{2}\right)^{2 k+1}=
\frac{1-y^{4 k+2}}{\left(1-y^2\right)^{2 k+1} }.
\]


\end{corollary}

\subsection{Non-negativity of the matrix entries for odd values of $m$}\label{nonnegsect}

In this section we present a detailed description of the non-negativity properties of the matrix $M$, thanks to the explicit forms for the entries $M_{1,j}$ obtained in Section \ref{explsect}. Throughout this section we still assume \eqref{genassump}.

By taking into account \eqref{M1jPjkDk}, \eqref{expldet}, \eqref{P1kexpl}, \eqref{poldef}, \eqref{Pjkexpl}, \eqref{Pjky}, and the fact that now $y\in(0,1)$ (see \eqref{ydef01}), the following corollary is evident.
\begin{corollary}\label{cor2} For a given pair $(\te,\nu)$
\[
M_{1,1}(2k+1,\te,\nu)\ge 0 \quad \Longleftrightarrow \quad \Pol\ge 0\quad\text{ (see } \eqref{poldef}\text{)},
\]
and for any $2\le j\le 2k+1$
\[
M_{1,j}(2k+1,\te,\nu)\ge 0 \quad \Longleftrightarrow \quad P_{j,k}(y)\ge 0\quad\text{ (see } \eqref{Pjky}\text{)}.
\]
\end{corollary}
\begin{figure}
\begin{center}
\includegraphics[width=0.5\textwidth]{fig_excepttopleft.pdf}
\caption{The typical behavior of the polynomials $P_{j,k}$ appearing in Corollary \ref{cor2} for $2\le j\le 2k+1$ and $k$ fixed: curves in shades of gray (or black) correspond to even $j$, while curves in shades of red (or orange) correspond to odd $j$ indices. Based on this figure, one can make the following observations. On the one hand, for each fixed and even $j$, $P_{j,k}$ is strictly increasing in $y$; however, for any fixed $y\in(0,1)$, $P_{j,k}$ is in general not monotone in its even index $j$. On the other hand, for each fixed and odd $j$, $P_{j,k}$ is in general not monotone in $y$; however, for any fixed $y\in(0,1)$, $P_{j,k}$ is strictly decreasing in its odd index $j$.}\label{fig_excepttopleft}
\end{center}
\end{figure}
The following lemma proves some of the observations about the polynomials $P_{j,k}$ suggested by Figure \ref{fig_excepttopleft} for even and odd indices $2\le j\le 2k+1$.
\begin{lemma}\label{lem2} Let us fix $y\in(0,1)$ arbitrarily. Then\\
\indent $\bullet$ for any $1\le\ell\le k$, $P_{2\ell,k}(y)>0$;\\
\indent $\bullet$ for any $2\le\ell\le k$, $P_{2\ell+1,k}(y)<P_{2\ell-1,k}(y)$. 
\end{lemma}
\begin{proof} For the even indices, we have
\[
P_{2\ell,k}(y)=y^{2 k-2 l+1}(1-y^{2 k+1})+y^{2 k+2 l-1}+y^{2 l-2}>0,\]
while for the odd indices,
\[
P_{2\ell+1,k}(y)-P_{2\ell-1,k}(y)=-(1 - y^2)\Big(y^{2 k+2 l-2}+y^{2 l-3}+y^{2 k-2 l}(1-y^{2k+1})\Big)<0.
\] 
\end{proof}
By combining Corollary \ref{cor2} and Lemma \ref{lem2}, we have obtained the following result, expressing the fact that the non-negativity of $M(2k+1,\te,\nu)$ is determined only by the polynomials appearing in the numerators of its top left and top right entries.
\begin{corollary}\label{cor3} For a given pair $(\te,\nu)$
\[
M_{1,1}(2k+1,\te,\nu)\ge 0 \quad \Longleftrightarrow \quad \Pol\ge 0 \quad \text{(see } \eqref{poldef}\text{)},
\]
and
\[
M_{1,j}(2k+1,\te,\nu)\ge 0 \text{  for each } 2\le j\le 2k+1 \quad \Longleftrightarrow \quad
\Por\ge 0\quad\text{(see }\eqref{pordef}\text{)}.
\]
\end{corollary}
The non-negativity of $M(2k+1,\te,\nu)$ has therefore been reduced to studying the simultaneous non-negativity of two parametric polynomials, $P_{L,k,\te}$ and $P_{R,k}$, over the $y$-interval $(0,1)$. The content of Lemmas \ref{lem3} and \ref{lem4} is illustrated by Figure \ref{fig_someplpr}.
\begin{lemma}[about the sign of $\Por$]\label{lem3}
Let us fix $k$ arbitrarily, and recall that by definition $\Por=y^{4 k}+y^{2 k+1}+y^{2 k-1}-1$. Then there is a unique $y\in(0,1)$ such that $\Por=0$.\\ 
Let 
\begin{equation}\label{yrdef}\yr \text{ denote this root.}\end{equation} 
Then $\Por<0$ for $y\in(0,\yr)$, and $\Por>0$ for $y\in(\yr,1)$.\\
Moreover, $\yr<y_R(k+1)$, $\lim_{k\to+\infty} \yr=1$, and
\begin{equation}\label{yrasympt}
\left(\sqrt{2}-1\right)^{\frac{1}{2 k-1}}<\yr < \left(\sqrt{2}-1\right)^{\frac{1}{2 k+1}}.
\end{equation}
\end{lemma}
\begin{proof}
For fixed $k$, the continuous function $y\mapsto\Por=y^{4 k}+y^{2 k+1}+y^{2 k-1}-1$ is strictly increasing, 
$P_{R,k}(0)<0$ and $P_{R,k}(1)>0$, hence there is a unique root. This root is strictly increasing in $k$, because the function $k\mapsto\Por$ is strictly decreasing for fixed $y\in(0,1)$. Finally notice that 
$y^{4 k}+y^{2 k+1}+y^{2 k-1}-1=0$ is equivalent to $\left(y^{2 k-1}+1\right) \left(y^{2 k+1}+1\right)=2$,
and for any $y\in(0,1)$ one has
\[
\left(y^{2 k+1}+1\right)^2<\left(y^{2 k-1}+1\right) \left(y^{2 k+1}+1\right)<\left(y^{2 k-1}+1\right)^2.
\]
From this we easily get \eqref{yrasympt} and also the limit of $\yr$ ($k\to +\infty$).
\end{proof}
\begin{remark}
The asymptotic series (as $k\to+\infty$) of both bounds in \eqref{yrasympt} has the form
\[
1+\frac{\ln \left(\sqrt{2}-1\right)}{2 k}+{\cal{O}}\left(\frac{1}{k^2}\right)\approx 
1-\frac{0.44069}{k}+{\cal{O}}\left(\frac{1}{k^2}\right).
\]
\end{remark}






\begin{lemma}[about the sign of $\Pol$]\label{lem4} Let us fix $k$ arbitrarily, and recall that by definition 
$\Pol=-\theta  y^{4 k+4}-(\theta -2) y^{4 k+2}+(\theta -2) y^2+\theta$.\\
(i) Suppose that $\frac{2k}{2k+1}\le\te\le1$. Then, for any $y\in(0,1)$, $\Pol>0$.\\
(ii) Suppose now that $0<\te<\frac{2k}{2k+1}$. Then there is a unique $y\in(0,1)$ such that $\Pol=0$.\\ 
Let 
\begin{equation}\label{yldef}\yl \text{ denote this root.}\end{equation} 
Then $\Pol>0$ for $y\in(0,\yl)$, and $\Pol<0$ for $y\in(\yl,1)$.\\
Moreover, on the one hand, for fixed $0<\te<\frac{2k}{2k+1}$, the function $k\mapsto\yl$ is strictly decreasing, and $\lim_{k\to+\infty} \yl=\sqrt{\frac{\te}{2-\te}}\in(0,1)$.\\
On the other hand, for fixed $k\in\nplus$, the function $\left(0,\frac{2k}{2k+1}\right)\ni\te\mapsto\yl$ is strictly increasing, and we have the one-sided limits $\lim_{\te\to0+0} \yl=0$ and $\lim_{\te\to\frac{2k}{2k+1}-0} \yl=1$.
\end{lemma}
\begin{proof}
We notice that the expression $\Pol$ is linear in $\te$, so by setting 
\[
\Theta(y,k):=\frac{2 y^2 \left(1-y^{4 k}\right)}{\left(1+y^2\right) \left(1-y^{4 k+2}\right)},
\]
we easily get for any $y\in(0,1)$ that
\begin{equation}\label{lem4equi}
\Pol \lesseqqgtr 0\quad \Longleftrightarrow \quad \te\lesseqqgtr\Theta(y,k),
\end{equation}
where the symbol $\lesseqqgtr$ denotes either $<$, or $=$, or $>$ on both sides of the equivalence. It is
seen that for fixed $k$ we have the one-sided limits
\begin{equation}\label{lem4lim}
\lim_{y\to 0+0}\Theta(y,k)=0\quad\text{and}\quad\lim_{y\to 1-0}\Theta(y,k)=\frac{2k}{2k+1}.
\end{equation}
Now we show that the function
\begin{equation}\label{Thetaincr}
(0,1)\ni y\mapsto \Theta(y,k)\quad\text{is strictly increasing.}
\end{equation}
The partial derivative
\[
\partial_y\Theta(y,k)=\frac{4 y \left(1-(2 k+1) y^{4 k}+(2 k+1) y^{4 k+4}-y^{8 k+4}\right)}{\left(1+y^2\right)^2 \left(1-y^{4 k+2}\right)^2}
\]
is positive, if $\widetilde{P}(y,k):=1-(2 k+1) y^{4 k}+(2 k+1) y^{4 k+4}-y^{8 k+4}>0$. But 
\[
\widetilde{P}(0,k)=1\quad\text{and}\quad\widetilde{P}(1,k)=0,
\]
so the positivity of $\widetilde{P}(y,k)$ will follow if we show that $y\mapsto\widetilde{P}(y,k)$ is strictly decreasing. Indeed,
\[
\partial_y\widetilde{P}(y,k)=-4 (2 k+1) y^{4 k-1} \widetilde{Q}(y,k),
\]
where
\[
\widetilde{Q}(y,k):=y^{4 k+4}-(k+1) y^4+k,
\]
hence it is enough to verify $\widetilde{Q}(y,k)>0$. And this is true, since $\widetilde{Q}(0,k)=k$, $\widetilde{Q}(1,k)=0$ and
\[
\partial_y \widetilde{Q}(y,k)=-4 (k+1) y^3 \left(1-y^{4 k}\right)<0.
\]
Now, as \eqref{Thetaincr} has been checked, it is obvious that continuity, \eqref{lem4equi}, \eqref{lem4lim} and \eqref{Thetaincr} imply statement (\textit{i}) of the lemma, and, at the same time, regarding statement (\textit{ii}) of the lemma, the existence of a unique root $\yl\in(0,1)$, the positivity of $P_{L,k,\te}$ on $(0,\yl)$, and the negativity of $P_{L,k,\te}$ on $(\yl,1)$.

We finally discuss the monotonicity and limit properties of the root $\yl$. For fixed $y\in(0,1)$, the function $k\mapsto\Theta(y,k)$ is strictly increasing, since
\[
\Theta(y,k+1)-\Theta(y,k)=\frac{2 \left(1-y^2\right)^2 y^{4 k+2}}{\left(1-y^{4 k+2}\right) \left(1-y^{4
   k+6}\right)}>0.
\]
This implies that, for any fixed $\te\in\left(0,\frac{2k}{2k+1}\right)$, the function $k\mapsto\yl$ is strictly decreasing. Moreover, for fixed $y\in(0,1)$, we see from the definition that $\lim_{k\to+\infty} \Theta(y,k)=\frac{2 y^2}{1+y^2}$,
so, due to \eqref{lem4equi} with ``equality'', one has for fixed $\te\in\left(0,\frac{2k}{2k+1}\right)$ that $y_{\infty}(\te):=\lim_{k\to+\infty} \yl$ solves $\te=\frac{2 y_{\infty}(\te)^2}{1+y_{\infty}(\te)^2}$; in other words, $y_{\infty}(\te)=\sqrt{\frac{\te}{2-\te}}\in(0,1)$. To show the validity of the last sentence of the lemma, we fix $k\in\nplus$, and simply take into account again \eqref{lem4equi} with ``equality'', \eqref{lem4lim} and \eqref{Thetaincr}.
\end{proof}
\begin{figure}
\begin{center}
\includegraphics[width=0.5\textwidth]{fig_someplpr.pdf}
\caption{The two solid curves show the functions $y\mapsto\Por$ for some $k=k_0$ (solid black) and 
 $k=k_1$ (solid red) with $k_0<k_1$.  The dashed black curves show the functions $y\mapsto\Pol$ for $k=k_0$ and for various values of $\te\in(0,1]$. Finally, the dotted red curves show the functions $y\mapsto\Pol$ for $k=k_1$ and for the same values of $\te\in(0,1]$.}\label{fig_someplpr}
\end{center}
\end{figure}




In order to return to the original variables $(\te,\nu)$ from the variable $y$---based on \eqref{fromytonu},  \eqref{yrdef} and \eqref{yldef}---we define
\begin{equation}\label{nurdef}
\nur:=\frac{2\yr}{1-\yr^2}\cdot \frac{1}{\te},
\end{equation}
and similarly,
\begin{equation}\label{nuldef}
\nul:=\begin{cases}
 \frac{2\yl}{1-\yl^2}\cdot \frac{1}{\te} & \text{for } 0<\te<\frac{2k}{2k+1}\\
 +\infty & \text{for } \frac{2k}{2k+1}\le \te\le 1.
\end{cases}
\end{equation}
The value $+\infty$ is introduced here for convenience so as to make our descriptions shorter.

A reformulation of Corollary \ref{cor3} in terms of the variables $(\te,\nu)$ is given below.
\begin{corollary}\label{cor4}
For any $k\in\nplus$ and $\te\in(0,1]$ we have 
\[
M_{1,1}(2k+1,\te,\nu)\ge 0 \quad \Longleftrightarrow \quad \nu\le\nul,
\] 
and
\[
M_{1,j}(2k+1,\te,\nu)\ge 0 \text{  for each } 2\le j\le 2k+1 \quad \Longleftrightarrow \quad \nu\ge\nur.
\] 
In particular, 
\[
M_{1,j}(2k+1,\te,\nu)\ge 0 \text{  for each } 1\le j\le 2k+1  \quad \Longleftrightarrow \quad \nur\le\nu\le\nul.
\] 
\end{corollary}
\begin{proof} By taking into account Corollary \ref{cor3}, Lemmas \ref{lem3} and \ref{lem4}, and the fact that the map in \eqref{fromytonu} 
\begin{equation}\label{cor4bijection}
(0,1)\ni y\mapsto\frac{2y}{1-y^2}\in(0,+\infty)\text{ is a strictly increasing bijection,}
\end{equation}
we get for fixed $k$ and $\te$ that $\Por\ge 0$ is equivalent to $\nu\ge\nur$, and
$\Pol\ge 0$ is equivalent to $\nu\le\nul$. In particular, due to the definition of $\nul$ in \eqref{nuldef}, this last inequality means that there is no upper bound on $\nu$ for $\frac{2k}{2k+1}\le \te\le 1$.
\end{proof}
Some growth rates, monotonicity and limit properties of $\nur$ and $\nul$---defined in 
\eqref{nurdef}--\eqref{nuldef}---are collected below; 
see also Figures \ref{fig_variousk} and \ref{fig_boundary}.
\begin{corollary}\label{cor5} (i) For any $k\in\nplus$ and $\te\in(0,1]$, we have $\nur<\nu_R(k+1,\theta)$, and
\begin{equation}\label{cor5lowerupper}
\frac{2 \left(\sqrt{2}+1\right)^{\frac{1}{2 k-1}}}{\left(\sqrt{2}+1\right)^{\frac{2}{2
   k-1}}-1}\cdot\frac{1}{\te}<\nur<\frac{2 \left(\sqrt{2}-1\right)^{\frac{1}{2 k+1}}}{1-\left(\sqrt{2}-1\right)^{\frac{2}{2
   k+1}}}\cdot\frac{1}{\te}.
\end{equation}
The asymptotic series for these lower and upper bounds have the form
\[
\left( \frac{2}{\ln \left(\sqrt{2}+1\right)}k\mp\frac{1}{\ln \left(\sqrt{2}+1\right)}+ {\cal{O}}\left(\frac{1}{k}\right)\right)\cdot\frac{1}{\te},
\]
being approximately
$
\left( 2.26919 k\mp1.13459+ {\cal{O}}\left(\frac{1}{k}\right)\right)\cdot\frac{1}{\te}.
$
In particular, $\lim_{k\to+\infty} \nur=+\infty$.\\
(ii) For fixed $0<\te<\frac{2k}{2k+1}$, $\nul>\nu_L(k+1,\theta)$ (and $\nul =+\infty$ for $\frac{2k}{2k+1}\le\te\le 1$). Finally, for fixed $\te\in(0,1)$, we have the limit
\begin{equation}\label{cor5klim}
\lim_{k\to+\infty} \nul=\frac{1}{1-\theta }\sqrt{\frac{2-\theta }{\theta }},
\end{equation}
and, for fixed $k\in\nplus$, the one-sided limits  
\begin{equation}\label{cor5thetalim}
\lim_{\te\to 0+0} \nul=+\infty=\lim_{\te\to\frac{2k}{2k+1}-0} \nul.
\end{equation}
\end{corollary}
\begin{proof} (\textit{i}) The monotonicity of $\nur$ in $k$ for fixed $\te$ follows from the monotonicity of 
$\yr$ in Lemma \ref{lem3} together with \eqref{cor4bijection}, and inequality \eqref{cor5lowerupper} is 
just \eqref{yrasympt} under the transformation \eqref{cor4bijection}.\\
(\textit{ii}) We similarly obtain the monotonicity of $\nul$ in $k$ for fixed $\te$, and the limit \eqref{cor5klim} from Lemma \ref{lem4} via \eqref{cor4bijection}, by also noting that
%\begin{equation}\label{cor5roots}
\[
\frac{2\sqrt{\frac{\te}{2-\te}}}{1-\left(\sqrt{\frac{\te}{2-\te}}\right)^2}\cdot \frac{1}{\te}=\frac{1}{1-\theta }\sqrt{\frac{2-\theta }{\theta }}.
\]
%\end{equation}
As for the $\te\to\frac{2k}{2k+1}-0$ limit in \eqref{cor5thetalim}, we know from Lemma \ref{lem4} that $\yl\to 1$ (from below), and $\lim_{y\to 1-0}\frac{2y}{1-y^2}=+\infty$, hence $\nul\to+\infty$ when $\te\to\frac{2k}{2k+1}-0$.

One needs to take care only when evaluating the $\te\to 0+0$ limit in \eqref{cor5thetalim} for fixed $k\in\nplus$,  since $\frac{2\yl}{1-\yl^2}\to 0$ and $\frac{1}{\te}\to+\infty$ in \eqref{nuldef} when $\te\to0+0$. But 
the monotonicity of $\nul$ in $k$ for fixed $\te$, and \eqref{cor5klim} imply for any $k$ and $\te\in(0,1)$ that 
\[
\nul\ge\frac{1}{1-\theta }\sqrt{\frac{2-\theta }{\theta }},
\]
and the right-hand side here tends to $+\infty$ as $\te\to 0+0$.
\end{proof}

\begin{figure}
\begin{center}
\includegraphics[width=0.48\textwidth]{fig_variousk.pdf}
\caption{The parameter regions in the $(\te,\nu)$ parameter plane ensuring $M(2k+1,\te,\nu)\ge 0$ for $k=1, 2, \ldots, 6$ (different values of $k$ are represented by different colors). The regions continue to extend to infinity ``upward'', but ``shrink'' in the horizontal direction as $k$ is increased.}\label{fig_variousk}
\end{center}
\end{figure}



\begin{figure}
\begin{center}
\includegraphics[width=0.48\textwidth]{fig_boundary.pdf}
\caption{A typical shaded region in Figure \ref{fig_variousk} for which $M(2k+1,\te,\nu)\ge 0$; in this particular case, for $k=1$. The gray region is described by the inequalities $\nur\le\nu\le\nul$. The black dotted curve represents the function $\te\mapsto\nur$, while the red dashed curve is the function 
$\te\mapsto\nul$, having a vertical asymptote at $\te=2k/(2k+1)$.}\label{fig_boundary}
\end{center}
\end{figure}



The following result explains why the ``left half'' of Figure \ref{fig_variousk} is ``empty'' (cf.~Corollary \ref{cor4})---the result is non-trivial, since for fixed $k$, $\lim_{\te\to 0+0} \nul=+\infty=\lim_{\te\to 0+0} \nur$ (cf.~Figure \ref{fig_boundary}).
\begin{lemma}\label{lem5} For any $k\in\nplus$ there is a unique $\te_k\in\left[\frac{1}{2},\frac{2k}{2k+1}\right)$  such that 
\[
\nur = \nul\ \ \  (\text{for } \te\in(0,1])\quad \Longleftrightarrow \quad \te= \te_k.
\]
This $\te_k$ also satisfies
\[
\nur < \nul\quad \Longleftrightarrow \quad \te> \te_k.
\]
Moreover, the sequence $\te_k$ is strictly increasing in $k$, and  $\te_1=\frac{1}{2}$. In particular, for any $k\in\nplus$ and $\te\in\left(0,\frac{1}{2}\right)$ we have 
\[
 \nur>\nul.
\] 
\end{lemma}
\begin{proof} Let us fix $k$. Due to \eqref{nurdef}--\eqref{nuldef}, $\nur$ is finite but $\nul$ is infinite for any $\te\in\left[\frac{2k}{2k+1},1\right]$, so $\nur = \nul$ cannot hold. For $\te\in\left(0,\frac{2k}{2k+1}\right)$, by also using \eqref{cor4bijection}, we have 
\[
\nur = \nul\quad \Longleftrightarrow \quad \frac{2\yr}{1-\yr^2}=\frac{2\yl}{1-\yl^2} \quad \Longleftrightarrow
\quad \yr=\yl.
\]
Here $\yr$ is independent of $\te$, and $k$ is fixed, so by definitions \eqref{yrdef} and \eqref{yldef} this means that $\te$ must be chosen in a way such that $P_{L,k,\te}(\yr)=0$. By using the notation introduced in the proof of Lemma \ref{lem4}, this is equivalent to $\te=\Theta(\yr,k)=:\te_k$. Hence, if $\nur = \nul$ holds for some $\te\in(0,1]$, then $\te=\te_k\in\left(0,\frac{2k}{2k+1}\right)$. Now, by Lemma \ref{lem3}, we have $\yr<y_R(k+1)$, and $\Theta$ is strictly increasing in its first argument (see \eqref{Thetaincr}), so the sequence $\te_k$ is also strictly increasing. 

The same monotonicity argument shows that $\nur < \nul$ holds for some $\te\in(0,1]$ if and only if $\te>\te_k$
(see \eqref{lem4equi} and the characterization of  $P_{L,k,\te}>0$ in Lemma \ref{lem4}). 

For $k=1$, one explicitly computes that
\begin{equation}\label{nurl1thetaconcrete}
\nu_R(1,\theta)=\frac{2}{\te}\quad\text{ and }\quad\nu_L(1,\theta)=\frac{2}{\sqrt{\theta  (2-3 \theta)}},
\end{equation}
so $\nu_R(1,\theta)=\nu_L(1,\theta) \Longleftrightarrow \te=\te_1=1/2$. Therefore, we have
$\te_k\in\left(\frac{1}{2},\frac{2k}{2k+1}\right)$ for $k\ge 2$, also implying that for any $k\in\nplus$ and 
$\te\in\left(0,\frac{1}{2}\right)$, we have $\nur>\nul$.
\end{proof}

The following theorem summarizes the results of Section \ref{section3}.
% in a way which is tailored to the applications. It describes the entrywise non-negativity of the discretization matrices for fixed values of $\te$---first determining the actual time-integration method, then choosing the number of spatial grid points $m=2k+1$ and the CFL number $\nu$. 
In the theorem, we assume $k\in\nplus$, $\te\in[0,1]$ and $\nu\in(0,+\infty)$.
\begin{theorem}\label{thm2}
\begin{itemize}\ 
\item[$\bullet$] Fix $0\le\te<1/2$ arbitrarily. Then  $M(2k+1,\te,\nu)\ge 0$ can never hold, i.e.~for any $k\in\nplus$ and $\nu>0$ there is at least one strictly negative entry of the matrix $M$.
\item[$\bullet$] Let $\te=1/2$. Then
\[
M\left(2k+1,\frac{1}{2},\nu\right)\ge 0\quad\Longleftrightarrow\quad k=1\text{ and } \nu=4\quad\text{(see }\eqref{rem10thetahalfmatrix}\text{)}.
\]
\item[$\bullet$] Fix $1/2<\te<1$ arbitrarily. Then there are finitely many values of $k$ for which there exists $\nu>0$ with $M(2k+1,\te,\nu)\ge 0$. For any such value of $k$, the set of admissible values of $\nu$ has the form $\nur\le\nu\le\nul$, with suitable constants $0<\nur\le\nul\le+\infty$ (the possible case $\nul=+\infty$ means that there is no upper but only a lower bound on $\nu$); see also Corollary \ref{cor5}.
\item[$\bullet$] Let $\te=1$. Then for each $k\in\nplus$ there is a constant $\nu_R(k,1)>0$ such that
\[
M(2k+1,1,\nu)\ge 0\quad\Longleftrightarrow\quad \nu\ge\nu_R(k,1).
\]
In addition, $\nu_R(k,1)<\nu_R(k+1,1)$ for any $k$, $\lim_{k\to+\infty} \nu_R(k,1)=+\infty$, and the two-sided estimates in \eqref{cor5lowerupper} with $\te=1$ hold.
\end{itemize}
\end{theorem}
\begin{proof} The case $\te=0$ has already been discussed at the beginning of Section \ref{section3}.
In general, for $\te\in\left(0,1\right]$, we know from Corollary \ref{cor4} that, for any $k$, the set of $\nu$ values for which $M(2k+1,\te,\nu)\ge 0$ holds has the form $\nur\le\nu\le\nul$. 

The range $\te\in\left(0,\frac{1}{2}\right)$ is covered by Lemma \ref{lem5}. 

For $\te=1/2$, \eqref{nurl1thetaconcrete} shows that for $k=1$ one has $\nu_R(1,1/2)=\nu_L(1,1/2)=4$. 
But for any $k\ge 2$ we know (see Corollary \ref{cor5}) that
\[
\nu_L(k,1/2)<\nu_L(1,1/2)=\nu_R(1,1/2)<\nu_R(k,1/2),
\]
hence $\nu_R(k,1/2)\le\nu_L(k,1/2)$ cannot hold for any $k\ge 2$.

For fixed $1/2<\te<1$, $\nul$ becomes finite for all sufficiently large $k$ (see \eqref{nuldef}). But according to Corollary \ref{cor5}, $\nul$ is decreasing in $k$ for $\te<\frac{2k}{2k+1}$, and 
$\lim_{k\to+\infty} \nur=+\infty$, so the inequality $\nur\le\nul$ can hold only for finitely many values of $k$.

Finally, for $\te=1$, $\nu_L(k,1)=+\infty$ and we can use Corollary \ref{cor5} (\textit{i}) with $\te=1$.
\end{proof}

\begin{remark}
The ``lower left corner point'' of each shaded region in Figure \ref{fig_variousk} corresponds to a pair 
$(\te,\nu)$  for which $\nu=\nur=\nul$. This means that here the leftmost and the rightmost entries of the first row of $M(2k+1,\te,\nu)$ simultaneously vanish (and the other entries are non-negative). For $k=1$, this happens for $\te=\te_1=1/2$ and $\nu=4$; the corresponding matrix is
\begin{equation}\label{rem10thetahalfmatrix}
M\left(3,\frac{1}{2},4\right)=\left(
\begin{array}{ccc}
 0 & 1 & 0 \\
 0 & 0 & 1 \\
 1 & 0 & 0 \\
\end{array}
\right).
\end{equation}
\end{remark}






\section{Other discretizations/Conclusions?}\label{SNIEP}

\subsection{Fourier spectral collocation}
Here we consider the spectral method that results from extending the
finite difference stencil to include the whole spatial grid.  The resulting
semi-discretization can again be written in the form \eqref{semi-discrete}
where the matrix $L$ is given by \eqref{eigen} but now the entries of the
diagonal matrix $\Lambda$ are
\begin{align}
    \lambda_{\ell+1} & = 
    \begin{cases}
        \frac{2\pi \ell}{m} & 0 \le \ell \le (m-1)/2 \\
        0 & \ell = m/2 \\
        \frac{2\pi (\ell-m)}{m} & (m+1)/2 \le \ell \le m-1.
    \end{cases}
\end{align}
The entries of the first row of this circulant matrix are again
given by \eqref{M-entries}.  Taking $\theta=1$ (backward Euler)
and recognizing that the imaginary part vanishes, this leads to
\begin{align}
    M_{1j} & = \frac{1}{m} \sum_{l=1}^{m} \frac{\cos(j\xi_\ell) + \nu \lambda_\ell \sin(j\xi_\ell)}{1+\nu^2 \lambda_{\ell}^2} \\
           & = \frac{1}{m}\left(1 + 2 \sum_{\ell=2}^{(m+1)/2} \frac{\cos(j\xi_\ell) + \nu\lambda_\ell \sin(j\xi_\ell)}{1+\nu^2\lambda_\ell^2}\right).
\end{align}

blah

\boxed{\text{MAYBE some sentences from dknotes.tex here?}}




\begin{thebibliography}{99}

 \bibitem{matmat}
D.~S.~Bernstein, Matrix Mathematics. Theory, Facts, and Formulas. Second edition, Princeton University Press, Princeton, NJ (2009), \href{https://doi.org/10.1515/9781400833344}{https://doi.org/10.1515/9781400833344}

\bibitem{SSPbook}
{S.~Gottlieb,  D.~I.~Ketcheson,  C.-W.~Shu}, {Strong Stability Preserving {R}unge--{K}utta and Multistep Time Discretizations}. {World Scientific Publishing, Hackensack, NJ} ({2011})

\bibitem{posconv}
I.~Fekete, D.~I.~Ketcheson, L.~L\'oczi, Positivity for convective semi-discretizations, J.~Sci.~Comput., Vol.~74, No.~1, 244--266 (2018), \href{https://doi.org/10.1007/s10915-017-0432-9}{https://doi.org/10.1007/s10915-017-0432-9}

%\bibitem{hairerwanner1}
%E. Hairer, S. N{\o}rsett, G. Wanner, Solving Ordinary Differential Equations I. Nonstiff
%Problems, Springer, Berlin (2009)

\bibitem{hundsdorferverwer}
W.~Hundsdorfer, J.~Verwer, Numerical Solution of Time-Dependent Advection-Diffusion-Reaction
Equations. Springer Series in Computational Mathematics, Vol.~33, Springer, Berlin (2003)    

\bibitem{hairerwanner}
E.~Hairer, G.~Wanner, Solving Ordinary Differential Equations II. Stiff
and Differential-Algebraic Problems. Springer, Berlin (2002)

\bibitem{nonnegmatr}
 A.~Berman, R.~J.~Plemmons, Nonnegative Matrices in the Mathematical Sciences. SIAM (1994)
 
 \bibitem{rojosoto}
O.~Rojo, R.~L.~Soto, Existence and construction of nonnegative matrices with complex spectrum, 
Lin.~Alg.~Appl., Vol.~368, 53--69 (2003), \href{https://doi.org/10.1016/S0024-3795(02)00650-X}{https://doi.org/10.1016/S0024-3795(02)00650-X}



\end{thebibliography}

\end{document}
